{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Coronavirus_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DonPeregrina/CoronaV_Challenge/blob/master/1._Coronavirus_Extract.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGHv-mTFRjBo",
        "colab_type": "text"
      },
      "source": [
        "# Proyecto de Minado de Tweets acerca del Coronavirus\n",
        "\n",
        "\n",
        "* Autor: Noé Amador Campos Castillo\n",
        "* Email: ama-noe@outlook.com\n",
        "* Github: NoeCampos22\n",
        "* Description: Notebook hecho para minar tweets.\n",
        "* Last Update: 22-Feb-2020\n",
        "* Modificación: Lista de palabras y #, 24-Feb-2020, se agregó el guardar en drive. Xochitl Morales "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYOlxL5bTZuS",
        "colab_type": "code",
        "outputId": "78be8df8-a53a-4ae0-bd68-9e4bb57497de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nwqGhGGRjBr",
        "colab_type": "text"
      },
      "source": [
        "### Descargar Tweepy\n",
        "Para utilizar esta notebook es necesario descargar el paquete llamado **Tweepy**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OUaNH1HRjBt",
        "colab_type": "code",
        "outputId": "aa65e6cf-6d6b-47d8-b6b2-e35c13381cb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "!pip install tweepy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.12.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.3.0)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy) (2.21.0)\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSUe_lFpRjBz",
        "colab_type": "text"
      },
      "source": [
        "### Credenciales\n",
        "Son las llaves necesarias para conectarse a la aplicación en Twitter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj-y3BkTRjB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ACC_TOKEN = \"1102066975541469184-YKkul4Fo6QQiesON8JoebU4FtsULCm\"\n",
        "ACC_TOKEN_SECRET = \"uDxxZ6MOWDVBPXCQgoW3ntNK7aAMmrUmCfD4B5vN5ClnN\"\n",
        "CON_KEY = \"sC497zDMxJVD7HDtHOFAq0PDW\"\n",
        "CON_KEY_SECRET = \"294N1lUZ7EwvjsTj3l52sMmi8lssooY8bjTkAwRZ9QQMbQXX63\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnZ7jTpMRjB5",
        "colab_type": "text"
      },
      "source": [
        "### Clase MyTweet \n",
        "Es una clase utilizada para filtrar la información dada por el objeto tweet dado por tweepy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2xZ73nlRjB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import datetime\n",
        "\n",
        "\n",
        "class myTweet:\n",
        "    \"\"\"\n",
        "    A class to summarize the original Tweet object received from\n",
        "    Tweepy (Twitter API for Python)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ogTweet):\n",
        "        \"\"\"\n",
        "        It is the constructor to my version of the tweet object.\n",
        "\n",
        "        Parameters:\n",
        "        - ogTweet: The tweet object.\n",
        "        \"\"\"\n",
        "\n",
        "        # Get tweet data\n",
        "        self.__getTweetData(ogTweet)\n",
        "\n",
        "        # Get if it is a retweet or not\n",
        "        self.__getRetweet(ogTweet)\n",
        "\n",
        "        # Get user information\n",
        "        self.__getUserData(ogTweet)\n",
        "\n",
        "        # Get all the data from the entities\n",
        "        self.__getFromEntities(ogTweet)\n",
        "\n",
        "        # Get the place data\n",
        "        self.__getFromPlace(ogTweet)\n",
        "\n",
        "    def __getTweetData(self, ogTweet):\n",
        "        \"\"\"\n",
        "        Private function to get data about the tweet object.\n",
        "\n",
        "        Parameters:\n",
        "        - ogTweet: The tweet object.\n",
        "        \"\"\"\n",
        "\n",
        "        if ogTweet != None:\n",
        "            self.tw_id_str = ogTweet['id_str']\n",
        "            self.tw_truncated = ogTweet['truncated']\n",
        "            self.tw_created_at = ogTweet['created_at']\n",
        "            self.tw_coordinates = ogTweet['coordinates']\n",
        "            self.tw_is_quote_status = ogTweet['is_quote_status']\n",
        "            self.tw_in_reply_to_user_id_str = ogTweet['in_reply_to_user_id_str']\n",
        "            self.tw_in_reply_to_status_id_str = ogTweet['in_reply_to_status_id_str']\n",
        "\n",
        "            # If the text has more than 140 chars, the full text is inside\n",
        "            # the extended_tweet object.\n",
        "            if 'extended_tweet' in ogTweet:\n",
        "                self.tw_text = ogTweet['extended_tweet']['full_text']\n",
        "\n",
        "            else:\n",
        "                self.tw_text = ogTweet['text']\n",
        "\n",
        "    def __getRetweet(self, ogTweet):\n",
        "        \"\"\"\n",
        "        Private function to get if the received tweet is a retweet or not.\n",
        "\n",
        "        Parameters:\n",
        "        - ogTweet: The tweet object.\n",
        "        \"\"\"\n",
        "        if 'retweeted_status' in ogTweet:\n",
        "            self.rt_isRetweet = True\n",
        "            self.rt_OgTweetID = ogTweet['retweeted_status']['id_str']\n",
        "            self.rt_OgRetwCount = ogTweet['retweeted_status']['retweet_count']\n",
        "            self.rt_OgFavCount = ogTweet['retweeted_status']['favorite_count']\n",
        "        else:\n",
        "            self.rt_isRetweet = False\n",
        "            self.rt_OgTweetID = \"\"\n",
        "            self.rt_OgRetwCount = 0\n",
        "            self.rt_OgFavCount = 0\n",
        "\n",
        "    def __getUserData(self, ogTweet):\n",
        "        \"\"\"\n",
        "        Private function to get information from the tweet's author\n",
        "\n",
        "        Parameters:\n",
        "        - ogTweet: The tweet object.\n",
        "        \"\"\"\n",
        "        if ogTweet != None:\n",
        "            # User information\n",
        "            self.usr_name = ogTweet['user']['name']\n",
        "            self.usr_id_str = ogTweet['user']['id_str']\n",
        "            self.usr_verified = ogTweet['user']['verified']\n",
        "            self.usr_location = ogTweet['user']['location']\n",
        "            self.usr_screenname = ogTweet['user']['screen_name']\n",
        "            self.usr_listedcount = ogTweet['user']['listed_count']\n",
        "            self.usr_friendscount = ogTweet['user']['friends_count']\n",
        "            self.usr_statusescount = ogTweet['user']['statuses_count']\n",
        "            self.usr_followerscount = ogTweet['user']['followers_count']\n",
        "            self.usr_favouritescount = ogTweet['user']['favourites_count']\n",
        "\n",
        "    def __getFromEntities(self, ogTweet):\n",
        "        \"\"\"\n",
        "        Private function to get the list of the hashtags, media files or urls\n",
        "        that are used on the tweet\n",
        "\n",
        "        Parameters:\n",
        "        - ogTweet: The tweet object.\n",
        "        \"\"\"\n",
        "        self.ent_urls = \"\"\n",
        "        self.ent_media = \"\"\n",
        "        self.ent_hashtags = \"\"\n",
        "\n",
        "        if 'media' in ogTweet['entities']:\n",
        "            for media in ogTweet['entities']['media']:\n",
        "                self.ent_media += media['expanded_url'] + \" | \"\n",
        "\n",
        "        for hasht in ogTweet['entities']['hashtags']:\n",
        "            self.ent_hashtags += hasht['text'] + \" | \"\n",
        "\n",
        "        for url in ogTweet['entities']['urls']:\n",
        "            self.ent_urls += url['url'] + \" | \"\n",
        "\n",
        "        self.ent_urls = self.ent_urls[:-3]\n",
        "        self.ent_media = self.ent_media[:-3]\n",
        "        self.ent_hashtags = self.ent_hashtags[:-3]\n",
        "\n",
        "    def __getFromPlace(self, ogTweet):\n",
        "        \"\"\"\n",
        "            Private function that checks if the tweet has information\n",
        "            about the place the tweet was made from.\n",
        "\n",
        "            Parameters:\n",
        "                - ogTweet: The tweet object.\n",
        "        \"\"\"\n",
        "\n",
        "        # Check if the place object exists or not and save it if so\n",
        "        if ogTweet['place'] != None:\n",
        "            self.geo_name = ogTweet['name']\n",
        "            self.geo_country = ogTweet['country']\n",
        "            self.geo_full_name = ogTweet['full_name']\n",
        "            self.geo_place_type = ogTweet['place_type']\n",
        "            self.geo_country_code = ogTweet['country_code']\n",
        "            self.geo_bounding_box = ogTweet['bounding_box']\n",
        "\n",
        "        else:\n",
        "            self.geo_name = \"\"\n",
        "            self.geo_country = \"\"\n",
        "            self.geo_full_name = \"\"\n",
        "            self.geo_place_type = \"\"\n",
        "            self.geo_country_code = \"\"\n",
        "            self.geo_bounding_box = {}\n",
        "\n",
        "    def serialize(self):\n",
        "        \"\"\"\n",
        "        It returns the object as a dictionary\n",
        "        \"\"\"\n",
        "        return self.__dict__\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjWWnitBRjCA",
        "colab_type": "text"
      },
      "source": [
        "### Programa de Minado\n",
        "Es el script que se encarga de conectarse a la app en Twitter y empezar a minar los tweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C53l9PBuRjCB",
        "colab_type": "code",
        "outputId": "421f4e0b-7774-45f0-84ba-30637d65b507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "# Imports from the Tweepy API\n",
        "from tweepy.streaming import StreamListener\n",
        "from tweepy import OAuthHandler\n",
        "from tweepy import Stream\n",
        "from tweepy import API\n",
        "\n",
        "# To check if the file exist\n",
        "import os.path\n",
        "\n",
        "# Another imports to parse the json\n",
        "import json\n",
        "import time\n",
        "import csv\n",
        "\n",
        "# Variable to store the pointer to the CSV file\n",
        "FILE_MINING = None\n",
        "# Variable to know if the output file already exists or not\n",
        "FILE_EXISTS = False\n",
        "# Variable to count how many tweets were mined\n",
        "TWEETS_COUNT = 0\n",
        "\n",
        "\n",
        "def Get_Authentication():\n",
        "    \"\"\"\n",
        "    Get the authentication of the twitter app\n",
        "    \"\"\"\n",
        "\n",
        "    # Validate the Credentials\n",
        "    Auth = OAuthHandler(CON_KEY, CON_KEY_SECRET)\n",
        "    # Validate the Acces Tokens\n",
        "    Auth.set_access_token(ACC_TOKEN, ACC_TOKEN_SECRET)\n",
        "    return Auth\n",
        "\n",
        "\n",
        "class MyStreamListener(StreamListener):\n",
        "    \"\"\"\n",
        "    Class in charge of getting the tweets\n",
        "    \"\"\"\n",
        "\n",
        "    def on_error(self, status):\n",
        "        # status 420 is a warning to stop doing this\n",
        "        if status == 420:\n",
        "            return False\n",
        "        # Print the error status\n",
        "        print(status)\n",
        "\n",
        "    def on_data(self, data):\n",
        "        try:\n",
        "            # Get the global variables\n",
        "            global FILE_EXISTS\n",
        "            global FILE_MINING\n",
        "            global TWEETS_COUNT\n",
        "\n",
        "            # Loads the tweet object\n",
        "            parsed = json.loads(data)\n",
        "\n",
        "            # Create the tweet object with the info we need and return the json\n",
        "            Tweet = myTweet(parsed).serialize()\n",
        "\n",
        "            # Object to write a dictionary on a csv\n",
        "            dictWriter = csv.DictWriter(\n",
        "                FILE_MINING, fieldnames=Tweet.keys(), delimiter=',', lineterminator='\\n')\n",
        "\n",
        "            # If the file did not exists\n",
        "            if not FILE_EXISTS:\n",
        "                # Writes the headers\n",
        "                dictWriter.writeheader()\n",
        "                FILE_EXISTS = True\n",
        "\n",
        "            # Write the dict on the file\n",
        "            dictWriter.writerow(Tweet)\n",
        "\n",
        "            # Plus one to the counter\n",
        "            TWEETS_COUNT += 1\n",
        "\n",
        "            # Print in the terminal\n",
        "            if TWEETS_COUNT % 30 == 0:\n",
        "                print('.')\n",
        "            else:\n",
        "                print('.', end=' ')\n",
        "\n",
        "            return True\n",
        "\n",
        "        except BaseException as e:\n",
        "            print(\"->Error on data: %s\" % str(e))   # Catch the error\n",
        "\n",
        "        return True\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # An array with the key phrases to filter the tweets\n",
        "    #keyWords = ['2019nCoV', 'coronavirus 2019', 'covid-19','Coronavirus Outbreak ', \n",
        "    #        'mortalidadCovid', 'virus wuhan', 'EpidemiaCovid', 'VirusCovid',\n",
        "    #        'C-O-V-I-D', 'PandemiaCovid'\n",
        "    #        'actualización coronavirus', 'coronavirus', 'covid', 'COVID', '#Coronavirus',\n",
        "    #        '#coronavirus', '#COVID19', '#CoronavirusMexico', '#CoronavirusChino', '#CoronaVirus'\n",
        "    #        '#CoronavirusOutbreak', '#covid', '#infodemiacovid', '#pandemiacovid',\n",
        "    #        '#fakenewscovid', '#coronavirusourbreak', '#2019ncov', '#Covid19'\n",
        "    #        '#2019covid', '#enfermedadcoronavirus','#covid2019', '#Covid_2019'\n",
        "    #           ]\n",
        "    keyWords = ['neumonia','atipica','#neumonia','neumonía atípica','atípica',\n",
        "                'neumonía','mexico','asociada']\n",
        "      #         '#Tecmi',\n",
        "      #        'tecmi','Tecmilenio','#tecmilenio','#tecmi'\n",
        "      #          '']\n",
        "    location = []\n",
        "    \n",
        "\n",
        "    print(\"====== Running App ======\")\n",
        "    try:\n",
        "        # Start to the listen tweets\n",
        "        Auth = Get_Authentication()\n",
        "        myStreamListener = MyStreamListener()\n",
        "        myStream = Stream(Auth, myStreamListener)\n",
        "\n",
        "        # Check if the CSV file already exits\n",
        "        if os.path.exists('TweetsExtract.csv'):\n",
        "            FILE_EXISTS = True\n",
        "\n",
        "        # Open the file where the tweets are going to be write\n",
        "        FILE_MINING = open('TweetsExtract.csv', 'a+',\n",
        "                           encoding='UTF-8', newline='')\n",
        "\n",
        "        print(\"\\n>> Listening tweets\")\n",
        "\n",
        "        # Filter the tweets by language (spanish) and the keywords\n",
        "        myStream.filter(languages=[\"es\"], track=keyWords, stall_warnings=True)\n",
        "\n",
        "    # To stop the program\n",
        "    except KeyboardInterrupt:\n",
        "        FILE_MINING.close()\n",
        "        print(\"\\n\\n>> Mining finished.\")\n",
        "        print(str(TWEETS_COUNT) +\n",
        "              \" tweets were written in the TweetsExtract.csv file\")\n",
        "        !cp TweetsExtract.csv \"drive/My Drive/Nlu\"\n",
        "    except Exception as err:\n",
        "        # Print if there is an error\n",
        "        FILE_MINING.close()\n",
        "        print(\"\\n\\n>> Mining finished.\")\n",
        "        print(str(TWEETS_COUNT) +\n",
        "              \" tweets were written in the TweetsExtract.csv file\")\n",
        "        !cp TweetsExtract.csv \"drive/My Drive/Nlu\"\n",
        "        print(err)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====== Running App ======\n",
            "\n",
            ">> Listening tweets\n",
            ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            ". . . . . . . . . . . . . . . . . . . . ->Error on data: 'name'\n",
            ". . . . . . . . . .\n",
            ". . . . . . . . . . . . . . . . . . . . . . . . ->Error on data: 'name'\n",
            ". . . . . .\n",
            ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            ". . . . . . . . . . . . . . . . . . . . . . . \n",
            "\n",
            ">> Mining finished.\n",
            "233 tweets were written in the coronavirusTweets_Tecmi.csv file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmuAF_c5gAeE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp coronavirusTweets_Tecmi.csv \"drive/My Drive/Nlu\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRc-MyV_RjCL",
        "colab_type": "code",
        "outputId": "75f2bec6-1cde-433a-cfa7-d1acecc7df59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/Nlu/coronavirusTweets_Tecmi.csv')\n",
        "df.count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tw_id_str                       50\n",
              "tw_truncated                    50\n",
              "tw_created_at                   50\n",
              "tw_coordinates                   0\n",
              "tw_is_quote_status              50\n",
              "tw_in_reply_to_user_id_str       7\n",
              "tw_in_reply_to_status_id_str     6\n",
              "tw_text                         50\n",
              "rt_isRetweet                    50\n",
              "rt_OgTweetID                    17\n",
              "rt_OgRetwCount                  50\n",
              "rt_OgFavCount                   50\n",
              "usr_name                        50\n",
              "usr_id_str                      50\n",
              "usr_verified                    50\n",
              "usr_location                    23\n",
              "usr_screenname                  50\n",
              "usr_listedcount                 50\n",
              "usr_friendscount                50\n",
              "usr_statusescount               50\n",
              "usr_followerscount              50\n",
              "usr_favouritescount             50\n",
              "ent_urls                        12\n",
              "ent_media                        6\n",
              "ent_hashtags                     9\n",
              "geo_name                         0\n",
              "geo_country                      0\n",
              "geo_full_name                    0\n",
              "geo_place_type                   0\n",
              "geo_country_code                 0\n",
              "geo_bounding_box                50\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}